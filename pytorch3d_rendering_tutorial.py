# -*- coding: utf-8 -*-
"""Pytorch3D Rendering Tutorial

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r-bl2wBtuWCchVciowMo5W_FibIc4S9-

# Pytorch3D Tutorial

Contents of tutorial:
* Installing Pytorch3D on Colab
* Mesh Rendering
* Point cloud Rendering

More tutorials available: https://github.com/facebookresearch/pytorch3d

## Installing Pytorch3D


It will be much faster if you switch to GPU runtime (Runtime > Change runtime type > Hardware Accelerator > GPU).
"""

import os
import sys
import torch

# Suppress scientific notation
torch.set_printoptions(sci_mode=False)

# Install PyTorch3D if necessary
need_pytorch3d=False

try:
    import pytorch3d
except ModuleNotFoundError:
    need_pytorch3d=True

if need_pytorch3d:
    !uv pip install --extra-index-url https://miropsota.github.io/torch_packages_builder pytorch3d==0.7.8+pt{torch.__version__.replace('+', '')}

# Set up starter code
!git clone https://github.com/learning3d/assignment1.git
!mv assignment1/* .
!uv pip install -r requirements.txt

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pytorch3d
import pytorch3d.io
from pytorch3d.vis.plotly_vis import plot_scene
from tqdm.auto import tqdm

import starter.utils

# This should print True if you are using your GPU
print("Using GPU:", torch.cuda.is_available())
if torch.cuda.is_available():
    device = torch.device("cuda")
else:
    device = torch.device("cpu")

"""## Rendering a Mesh

To render a mesh, we need 3 components:

* A mesh to render
* A camera to render from
* A renderer (consisting of a rasterizer and shader)

### Setting up a mesh
"""

vertices, face_props, text_props = pytorch3d.io.load_obj("data/cow.obj")
faces = face_props.verts_idx

# Alternatively, we can use the wrapper from the starter code to load a mesh.
vertices, faces = starter.utils.load_cow_mesh(path="data/cow.obj")

print("Vertices", vertices.shape)
print("Faces", faces.shape)

print("vertices: ", vertices[0])
print("faces: ", faces[0])

faces.min(), faces.max()

# All Pytorch3D elements need to be batched!
vertices = vertices.unsqueeze(0)  # 1 x N_v x 3
faces = faces.unsqueeze(0)  # 1 x N_f x 3

print("Vertices", vertices.shape)
print("Faces", faces.shape)

texture_rgb = torch.ones_like(vertices) # N X 3
texture_rgb = texture_rgb * torch.tensor([0.7, 0.7, 1])
textures = pytorch3d.renderer.TexturesVertex(texture_rgb) # important
print(texture_rgb)
print(texture_rgb.shape)

meshes = pytorch3d.structures.Meshes(
    verts=vertices, # batched tensor or a list of tensors
    faces=faces,
    textures=textures,
)
meshes = meshes.to(device)  # Move mesh to GPU

print(meshes.verts_padded().shape)
print(meshes.faces_padded().shape)

"""### Setting up a camera"""

R = torch.eye(3).unsqueeze(0)
T = torch.tensor([[0, 0, 3]])

# world -> view transforms
# view_T_world @ world = view

cameras = pytorch3d.renderer.FoVPerspectiveCameras(
    R=R,
    T=T,
    fov=60,
    device=device,
)

cameras.get_camera_center()

transform = cameras.get_world_to_view_transform()
transform.get_matrix()

"""### Setting up a Renderer

Rasterizer: Given a pixel, which triangles correspond to it?

Shader: Given triangle, texture, lighting, etc, how should the pixel be colored?
"""

image_size = 512

raster_settings = pytorch3d.renderer.RasterizationSettings(image_size=image_size)
rasterizer = pytorch3d.renderer.MeshRasterizer(
    raster_settings=raster_settings,
)
shader = pytorch3d.renderer.HardPhongShader(device=device)
renderer = pytorch3d.renderer.MeshRenderer(
    rasterizer=rasterizer,
    shader=shader,
)

# Alternatively, use the renderer wrapper
renderer = starter.utils.get_mesh_renderer(image_size=image_size, device=device)

"""### Render an image"""

image = renderer(meshes, cameras=cameras)
print(image.shape)

image = image[0].cpu().numpy()
plt.imshow(image)

lights = pytorch3d.renderer.PointLights(location=[[0, 0, -3]], device=device)
image = renderer(meshes, cameras=cameras, lights=lights)
plt.imshow(image[0].cpu().numpy())

plot_scene({
    "figure": {
        "Mesh": meshes,
        "Camera": cameras,
    }
})

"""### Common Rendering Problems

* Nothing is visible
    * Check Camera center
    * Check the Camera world_to_view transform. Try applying the transform to the origin or specific vertices of the mesh.
    * Use the Plotly visualization.
* Lights doesn't seem to do anything
    * Make sure there's no typo (must be `renderer(..., lights=lights)` and not `light=lights`)
    * Check the position of the light

### Transformations

2 ways to apply geometric operations:
* Move the mesh
* Move the camera
"""

relative_rotation = pytorch3d.transforms.euler_angles_to_matrix(
    torch.tensor([0, np.pi/2, 0]), "XYZ"
)
relative_rotation

meshes2 = pytorch3d.structures.Meshes(
    verts=vertices @ relative_rotation,
    faces=faces,
    textures=textures,
).to(device)

image = renderer(meshes2, cameras=cameras, lights=lights)
plt.imshow(image[0].cpu().numpy())

cameras2 = pytorch3d.renderer.FoVPerspectiveCameras(
    R=relative_rotation.unsqueeze(0),
    T=[[0, 0, 3]],
    device=device
)

image = renderer(meshes, cameras=cameras2, lights=lights)
plt.imshow(image[0].cpu().numpy())

transform = cameras2.get_world_to_view_transform()
transform.get_matrix()

plot_scene({
    "Mesh1": {
        "Mesh": meshes,
        "Camera1": cameras,
        "Camera2": cameras2,
    },
    "Mesh2": {
        "Mesh": meshes2,
        "Camera1": cameras,
        "Camera2": cameras2,
    },
}, ncols=2)

num_views = 12
R, T = pytorch3d.renderer.look_at_view_transform(
    dist=3,
    elev=0,
    azim=np.linspace(-180, 180, num_views, endpoint=False),
)
print("R", R.shape)
print("T", T.shape)
many_cameras = pytorch3d.renderer.FoVPerspectiveCameras(
    R=R,
    T=T,
    device=device
)
images = renderer(meshes.extend(num_views), cameras=many_cameras, lights=lights)

fig, axs = plt.subplots(3, 4)
axs = axs.flatten()
for i, image in enumerate(images):
    ax = axs[i]
    ax.imshow(image.cpu())
    ax.axis("off")

plot_scene({
    "All Views": {
        "Mesh": meshes,
        "Cameras": many_cameras,
    },
})

"""### Playing with Texture"""

texture_rgb = vertices.clone()
texture_rgb = (texture_rgb - texture_rgb.min()) / (texture_rgb.max() - texture_rgb.min())
texture_rgb /= texture_rgb.norm(dim=2, keepdim=True)
textures_rainbow = pytorch3d.renderer.TexturesVertex(texture_rgb.to(device))
meshes.textures = textures_rainbow

image = renderer(meshes, cameras=cameras, lights=lights)
plt.imshow(image[0].cpu().numpy())

vertices, face_props, text_props = pytorch3d.io.load_obj("data/cow.obj")
faces = face_props.verts_idx
vertices = vertices.unsqueeze(0)
faces = faces.unsqueeze(0)
verts_uvs = text_props.verts_uvs
faces_uvs = face_props.textures_idx

texture_map = plt.imread("data/cow_texture.png")
plt.imshow(texture_map)

textures_uv = pytorch3d.renderer.TexturesUV(
    maps=torch.tensor([texture_map]),
    faces_uvs=faces_uvs.unsqueeze(0),
    verts_uvs=verts_uvs.unsqueeze(0),
).to(device)

meshes.textures = textures_uv
image = renderer(meshes, cameras=cameras, lights=lights)
plt.imshow(image[0].cpu().numpy())

"""## Rendering Pointclouds

We will need:

* A point cloud
* A camera
* A point renderer

### Setting up Point Cloud
"""

coords = torch.randn(1000, 3)
rgb = torch.ones_like(coords) * torch.tensor([0.7, 0.7, 1])

print("Coords:", coords.shape)
print("RGB:", rgb.shape)

pointcloud = pytorch3d.structures.Pointclouds(
    points=coords.unsqueeze(0),
    features=rgb.unsqueeze(0),
).to(device)

renderer = starter.utils.get_points_renderer(device=device, radius=0.03)

image = renderer(pointcloud, cameras=cameras)
plt.imshow(image[0].cpu())

plot_scene({
    "Pointcloud": {
        "Pointcloud": pointcloud,
        "Camera": cameras,
    },
})

rgb = coords.clone()
rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())

pointcloud = pytorch3d.structures.Pointclouds(
    points=coords.unsqueeze(0),
    features=rgb.unsqueeze(0),
).to(device)

image = renderer(pointcloud, cameras=cameras)
plt.imshow(image[0].cpu())

"""### Rendering Parametric Functions

Equation of a sphere with radius $r$ with center $(x_0, y_0, z_0)$:

$$x = x_0 + r * \sin \theta \cos\phi$$
$$y = y_0 + r * \cos \theta $$
$$z = z_0 + r * \sin\theta \sin\phi$$
"""

num_samples = 1000
r = 1
x_0 = 0
y_0 = 0
z_0 = 0

phi = torch.linspace(0, 2 * np.pi, num_samples)
theta = torch.linspace(0, 2 * np.pi, num_samples)
Phi, Theta = torch.meshgrid(phi, theta, indexing="ij")

print("Phi", Phi.shape)
print("Theta", Theta.shape)

x = x_0 + r * torch.sin(Theta) * torch.cos(Phi)
y = y_0 + r * torch.cos(Theta)
z = z_0 + r * torch.sin(Theta) * torch.sin(Phi)

points = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=1)
color = (points - points.min()) / (points.max() - points.min())

sphere_point_cloud = pytorch3d.structures.Pointclouds(
    points=[points], features=[color],
).to(device)

renderer = starter.utils.get_points_renderer(radius=0.01)

image = renderer(sphere_point_cloud, cameras=cameras)
plt.imshow(image[0].cpu())

plot_scene({
    "Pointcloud": {
        "Pointcloud": sphere_point_cloud,
        "Camera": cameras,
    },
})